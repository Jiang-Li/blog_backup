---
title: "Commenly-used Script"
author: ''
date: '2018-02-06'
---

```{r setup, include=F}
library(tidyverse)
# library(reticulate)
# knitr::opts_chunk$set(engine.path = '/Library/Frameworks/Python.framework/Versions/3.6/bin/python3')
```

I often use R, Python, SAS, SQL, and Bash in different
tasks at the same time. To make the switch between different languages easier, I built a list of the commonly-used script for a quick reference.

A simulated sample data set with missing values and duplicated values was used. 

```{r}
set.seed(1)
N <- 1000
df <- tibble(
dimension1 = sample(c("I", "II", "III"), N, replace = T),
dimension2 = sample(c("A", "B", "C"), N, replace = T),
measure1 = sample(1:10, N, replace = T),
measure2 = sample(1:10, N, replace = T)
)

df <- as_tibble(lapply(df, 
                       function(r) 
                         r[sample(c(TRUE, NA), 
                                  prob = c(0.85, 0.15), 
                                  size = length(r), 
                                  replace = TRUE)]
                       )
                )

head(df)

```


## Row and Column

### R

```{r, eval=T}
# row count
nrow(df) 
df %>% count()

# column names
names(df) 

# data types
lapply(df, class) 
```


### Python
```{python, eval=F}
# row count
df.shape[0]

# column names
list(df) 

# data types
df.dtypes  
```


### SAS
```
PROC CONTENTS DATA=df;
RUN;
```

### SQL
```{sql, eval=F}
/* row count */
SELECT COUNT(*) FROM df 

/* column names */
SELECT TOP 0 * FROM df 

/* data types */  
SELECT * FROM INFORMATION_SCHEMA.COLUMNS  
```

### Bash

```{bash, eval=F}
# row count
wc -l  filename 

# column names
head -1 filename 
```

## Missing Values

### R

```{r, eval=T}
# count missing by columns
colSums(is.na(df)) 

# drop rows with missing
na.omit(df) 

# drop rows with all missing
df[rowSums(!is.na(df)) > 0, ] 

# drop columns with all missing
df[colSums(!is.na(df)) > 0]
```

```{r, eval=T}
# fill all missing by 0
df %>% replace(., is.na(.), 0)

# fill missing by columns
df %>% replace_na(list(dimension1 = "Unknown", measure1 = 0)) 
```

### Python

```{python, eval=F}
# count missing by columns
df.isnull().sum()

# drop any missing
df.dropna() 

# drop rows with all missing
df.dropna(how="all") 

# drop columns with all missing
df.dropna(axis=1, how='all') 

# fill all missing by 0
df.fillna(0)

# fill missing by columns
df.fillna(value = {"dimension1": "Unknown", "measure1": 0})

```


## Unique

### R

```{r, eval=T}

# unique row
df %>% distinct()

# unique row by columns
df %>% distinct(dimension1, dimension2, .keep_all = T)

```

### Python

```{python, eval=F}
# unique row
df.drop_duplicates()

# unique row by columns
df.drop_duplicates(subset=('dimension1', 'dimension2'))
```

## Level Count

### R

```{r, eval=T}

# distribution
table(df$dimension1)

# contingency table
table(df$dimension1, df$dimension2)

```

### Python

```{python, eval=F}

# distribution
df.dimension1.value_counts()

# contingency table
pd.crosstab(df.dimension1, df.dimension2)

```


## Summary

### R

```{r, eval=T}

# summarize the total, percent, ratio, and ratio

df %>% 
  group_by(dimension1) %>% 
  summarise(
    measure1 = sum(measure1, na.rm = T),
    measure2 = sum(measure2, na.rm = T),
    count = n()
  ) %>% 
  mutate(
    measure1_percent = measure1/sum(measure1),
    ratio = measure1/measure2
  ) %>% 
  mutate(
    ratio_relativity = ratio/(sum(measure1)/sum(measure2))
  )

```

### Python

```{python, eval=F}

# summarize the total, percent, ratio, and relativity
def oneway(g):
  return(
    pd.Series({
      "measure1": g.measure1.sum(),
      "measure2": g.measure2.sum(),
      "count": len(g),
      "measure1_percent": g.measure1.sum()/df.measure1.sum(),
      "ratio": g.measure1.sum()/g.measure2.sum(),
      "ratio_relativity":
        (g.measure1.sum()/g.measure2.sum())/ 
        (df.measure1.sum()/df.measure2.sum())
    })
  )
  
df.groupby("dimension1").apply(oneway)

```


## Merge

### R

```{r, eval=T}
# join tables with different key names
df2 <- df %>%
  group_by(dimension1, dimension2) %>%
  summarise(
    measure3 = sum(measure1, na.rm = T),
    measure4 = sum(measure2, na.rm = T)
  ) %>%
  rename(dimension3 = dimension1, dimension4 = dimension2)

left_join(df, df2,
  by = c(
    "dimension1" = "dimension3",
    "dimension2" = "dimension4"
  )
)
```

### Python

```{python, eval=F}
# join tables with different key names
pd.merge(df, df2,
  how="left", 
  left_on=["dimesnion1", "dimesnion2"],
  right_on=["dimesnion3", "dimesnion4"]
)

```

## Reshape

### R

```{r, eval=T}

# wide to long
df_reshape <- df %>% gather(c("measure1", "measure2"), 
                            key = "measure", value = "values")

# long to wide: the value must be unqiue by other variales
df_reshape %>%
  group_by(dimension1, dimension2, measure) %>%
  summarise(values = sum(values, na.rm = T)) %>% 
  spread(key = measure, value = values)

```

### Python

```{python, eval=F}

df_reshape = pd.melt(df,
                     id_vars=['dimension1', 'dimension2'],
                     value_vars=['measure1', 'measure2'])

(df_reshape.groupby(['dimension1', 'dimension2', 'variable'],
                    as_index=False)
           .value.sum()
           .pivot_table(index=['dimension1', 'dimension2'],
                        columns='variable', values='value'))

```
