---
title: "R + H2O for Insurance Rating"
date: '2018-02-25'
---

Insurance rating models predict risk, which is usually represented by pure premium; i.e., the loss normalized by the covered time (exposure) $\frac {loss}{exposure}$. GLM (Generalized Linear Model) is the major method using in industry. Insurance data are highly imbalanced. When the data are not credible enough, pure premium is predicted by frequency $\frac {claimCount}{coveredTime}$ and severity $\frac {loss}{claimCount}$, respectively, because the frequency is more credible. 

Here I would like to show how to predict pure premium using frequency and severity in R and H2O - transitioning away from the industry standard of SAS without any loss in model accuracy.

## Data and Methods

The data set is the dataCar in insuranceDate library. I used the following explanatory variables:

variables | note
----------|---------------------------------------------
veh_value | in $10k unit; an approximation of vehicle symbol
exposure  | in 0~1; probably earned car year
numclaims | claim count
claimcst0 | loss amount
veh_body  | body type, a categorical variable
veh_age   | age of vehicle
gender    | a categorical veritable
area      | a categorical variable; an approximation of the territory agecat    | driver age| age of driver

```{r setup, include=F}
library(insuranceData)
library(scales)
data(dataCar)
```

```{r}
str(dataCar)
```

## Modeling

Usually the insurance data set is big. To make the the code to be easily scaled up, I used the H2O.

```{r message=FALSE, warning=FALSE}
library(h2o)

h2o.init(
  nthreads = -1,
  max_mem_size = "4G"
)

h2o.no_progress()

df <- as.h2o(dataCar)
```



```{r}
varList <- c(
  "veh_value",
  "exposure",
  "numclaims",
  "claimcst0",
  "veh_body",
  "veh_age",
  "gender",
  "area",
  "agecat"
)
df <- df[, varList]
df$PP <- df$claimcst0 / df$exposure

# the features used in modeling
varModel <- c(
  "veh_value",
  "veh_body",
  "veh_age",
  "gender",
  "area",
  "agecat"
)

df$frequency <- df$numclaims / df$exposure
df$severity <- df$claimcst0 / df$numclaims

print("Percentage of missing values in frequency and severity:")
percent(h2o.sum(is.na(df$frequency)) / nrow(df))
percent(h2o.sum(is.na(df$severity)) / nrow(df))

# The sample data set is too small. I did not split them to train and test.
train <- df
test <- df

```


First, frequency is modeled. Please note that the Poisson distribution requires a whole number as the response variable, so exposure, the denominator of frequency, is treated by the offset.
```{r}

train$logExp <- h2o.log(train$exposure) # offset

freqFit = h2o.glm(y = "numclaims",
                  x = varModel,
                  training_frame = train,
                  offset_column = "logExp",
                  family = "poisson",
                  link = "log",
                  missing_values_handling = "Skip",
                  solver = "IRLSM",
                  lambda = 0,
                  remove_collinear_columns = T,
                  compute_p_values = T
)

```

Then, severity is modeled.

```{r}

sevFit = h2o.glm(y = "severity",
                 x = varModel,
                 training_frame = train,
                 family = "gamma",
                 link = "log",
                 missing_values_handling = "Skip",
                 solver = "IRLSM",
                 lambda = 0,
                 remove_collinear_columns = T,
                 compute_p_values = T
)

```


## Output

The predicted pure premium was calculated using the frequency and severity factors. 

```{r}
library(dplyr)

summaryFactorGLM <- function(fitModles) {
  # Summarize the factors.
  #
  # Args:
  #  fitModles: list of h2o modles: frequency and severity
  #
  # Returns:
  #   A data frame of the combined factor table.

  freqFit <- fitModles[["frequency"]]
  sevFit <- fitModles[["severity"]]

  freqCoef <- as.data.frame(freqFit@model$coefficients_table)
  freqCoef[freqCoef$names == "Intercept", "names"] <- "freqIntercept"

  freqCoef <- freqCoef %>%
    mutate(
      frequencyFactor = exp(coefficients)
    ) %>%
    select(
      names,
      frequencyFactor,
      frequencyEstimate = coefficients
    )

  sevCoef <- sevFit@model$coefficients_table

  sevCoef[sevCoef$names == "Intercept", "names"] <- "sevIntercept"

  sevCoef <- sevCoef %>%
    mutate(
      severityFactor = exp(coefficients)
    ) %>%
    select(
      names,
      severityFactor,
      severityEstimate = coefficients
    )

  # pure premium
  ppCoef <- full_join(freqCoef, sevCoef, by = "names")

  ppCoef$factor <- ppCoef$frequencyFactor * ppCoef$severityFactor

  # assign the factor of intercept
  ppCoef[ppCoef$names == "sevIntercept", "factor"] <-
    ppCoef[ppCoef$names == "sevIntercept", "severityFactor"]
  ppCoef[ppCoef$names == "freqIntercept", "factor"] <-
    ppCoef[ppCoef$names == "freqIntercept", "frequencyFactor"]

  # seperate the parameter and level, remove the intercept
  ppCoef$parameter <- sapply(strsplit(ppCoef$names, "\\."), "[", 1)
  ppCoef$level <- sapply(strsplit(ppCoef$names, "\\."), "[", 2)
  ppCoef$names <- NULL


  return(ppCoef)
}


factorDF <-
  summaryFactorGLM(list(frequency = freqFit, severity = sevFit)) %>% 
  select(parameter, level, factor)

factorDF
```


