<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.39" />


<title>Insurance Rating Model using R - Jiang&#39;s Blog</title>
<meta property="og:title" content="Insurance Rating Model using R - Jiang&#39;s Blog">



  








<link href='//cdn.bootcss.com/highlight.js/9.11.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/post/">Blog</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">10 min read</span>
    

    <h1 class="article-title">Insurance Rating Model using R</h1>

    
    <span class="article-date">2018/02/25</span>
    

    <div class="article-content">
      <div id="TOC">
<ul>
<li><a href="#data-and-methods">Data and Methods</a></li>
<li><a href="#glm">GLM</a></li>
<li><a href="#glm-tweedie">GLM tweedie</a></li>
<li><a href="#random-forest">Random Forest</a></li>
<li><a href="#gbm">GBM</a></li>
</ul>
</div>

<p>Insurance rating models predict risk, which is usually represented by pure premium; i.e., the incurred loss normalized by exposure, for example, the earned car year. GLM (Generalized Linear Model) is the most popular method mostly because the results are interpretable.</p>
<p>GLM SAS, R, tweedie vs freq sev</p>
<!-- Also, In the insurance modeling, the variation of response could be nonlinear and very complicated. I am curious that how how this complexity can be well caught by GLM's logarithm link function. It is well known that the tree algorithm may predict the non linear response more accurately, although the inference is not straightforward. Thus, I would like to implement the rating model by tree algorithm, and compare the restuls to -->
<!-- GLM. -->
<p>First, some funcions are defined for model evaluaton.</p>
<p>detailsâ€¦</p>
<pre class="r"><code>library(tidyverse)

summaryFactorGLM &lt;- function(fitModles) {
  # Summarize the factors.
  #
  # Args:
  #  fitModles: list of h2o modles: frequency and severity
  #
  # Returns:
  #   A data frame of the combined factor table.  
  
  freqFit &lt;- fitModles[[&quot;frequency&quot;]]
  sevFit &lt;- fitModles[[&quot;severity&quot;]]
  
  freqCoef &lt;- as.data.frame(freqFit@model$coefficients_table)
  freqCoef[freqCoef$names == &quot;Intercept&quot;, &quot;names&quot;] &lt;- &quot;freqIntercept&quot;
  
  freqCoef &lt;- freqCoef %&gt;% 
    mutate(
      frequencyFactor = exp(coefficients)
    ) %&gt;% 
    select(
      names, 
      frequencyFactor, 
      frequencyEstimate = coefficients
  )
  
  
  sevCoef &lt;- sevFit@model$coefficients_table
  
  sevCoef[sevCoef$names == &quot;Intercept&quot;, &quot;names&quot;] &lt;- &quot;sevIntercept&quot;
  
  sevCoef &lt;- sevCoef %&gt;% 
    mutate(
      severityFactor = exp(coefficients)
    ) %&gt;% 
    select(
      names, 
      severityFactor, 
      severityEstimate = coefficients
  )
  
  # pure premium
  ppCoef &lt;- full_join(freqCoef, sevCoef, by = &quot;names&quot;)
  
  ppCoef$factor &lt;- ppCoef$frequencyFactor * ppCoef$severityFactor

  # assign the factor of intercept
  ppCoef[ppCoef$names == &quot;sevIntercept&quot;, &quot;factor&quot;] &lt;- 
    ppCoef[ppCoef$names == &quot;sevIntercept&quot;, &quot;severityFactor&quot;]
  ppCoef[ppCoef$names == &quot;freqIntercept&quot;, &quot;factor&quot;] &lt;- 
    ppCoef[ppCoef$names == &quot;freqIntercept&quot;, &quot;frequencyFactor&quot;]
  
  # seperate the parameter and level, remove the intercept
  ppCoef$parameter &lt;- sapply(strsplit(ppCoef$names, &quot;\\.&quot;), &quot;[&quot;, 1)
  ppCoef$level &lt;- sapply(strsplit(ppCoef$names, &quot;\\.&quot;), &quot;[&quot;, 2)
  ppCoef$names &lt;- NULL
  
  
  return(ppCoef)
}

evaluateModel &lt;- function(df){
  
  eva &lt;- as.data.frame(df)
  checkMAE(eva, &quot;predict_PP&quot;, &quot;PP&quot;)
  checkLift(eva, &quot;predict_PP&quot;, &quot;PP&quot;, &quot;exposure&quot;, &quot;claimcst0&quot;, 10)
  checkGini(eva, &quot;predict_PP&quot;, &quot;exposure&quot;, &quot;claimcst0&quot;)
  
}


checkMAE &lt;- function(df, predictPP, PP) {
  
  print(paste0(&quot;The percent of predicted total pure premium: &quot;, 
               percent(sum(df[,predictPP], na.rm = T)/sum(df[,PP], na.rm = T))
               ))
   
  print(paste0(&quot;The MAE of pure premium is: &quot;, 
               round(mean(abs(df[,PP] - df[,predictPP]), na.rm = T), 2)
               ))
}

checkLift &lt;- function(df, predictPP, PP, exposure, IL, N) {
  predictPP &lt;- rlang::sym(predictPP)
  PP &lt;- rlang::sym(PP)
  exposure &lt;- rlang::sym(exposure)
  IL &lt;- rlang::sym(IL)

  liftPredPP &lt;- df %&gt;%
    arrange(!!predictPP) %&gt;% 
    mutate(cumECY = cumsum(!!exposure)) %&gt;% 
    mutate(tier = cut(cumECY, breaks = N)) %&gt;%
    group_by(tier) %&gt;% 
    summarise(predictPP = dollar(sum(!!IL)/sum(!!exposure)))
  
  liftPP &lt;- df %&gt;%
    arrange(!!PP) %&gt;% 
    mutate(cumECY = cumsum(!!exposure)) %&gt;% 
    mutate(tier = cut(cumECY, breaks = N)) %&gt;%
    group_by(tier) %&gt;% 
    summarise(realPP = dollar(sum(!!IL)/sum(!!exposure)))
  print(bind_cols(liftPredPP, liftPP))
}
  
checkGini &lt;- function(df, PP, exposure, loss, N = 100) {
  
  PP &lt;- rlang::sym(PP)
  exposure &lt;- rlang::sym(exposure)
  loss &lt;- rlang::sym(loss)
  
  
  gini &lt;- df %&gt;%
    arrange(!!PP) %&gt;% 
    mutate(cumECY = cumsum(!!exposure)/sum(!!exposure)) %&gt;% 
    mutate(tierECY = cut(cumECY, N, labels = seq(0, 1, 1/N)[-1] )) %&gt;% 
    group_by(tierECY) %&gt;% 
    summarise(loss = sum(!!loss)) %&gt;% 
    mutate(cumLoss = cumsum(loss)/sum(loss))

  p &lt;- gini %&gt;% ggplot(aes(x = tierECY, y = cumLoss)) +
    geom_point() +
    xlab(&quot;Cumulative Exposure&quot;) +
    ylab(&quot;Cumulative Loss&quot;) +
    ggtitle(&quot;Gini&quot;) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    scale_x_discrete(breaks = seq(0.01, 1, by = 5/N))
  
  calcGini &lt;- gini %&gt;%
    mutate(height = cumLoss,
           width = 1/N) %&gt;%
    select(height, width) %&gt;% 
    mutate(area = width * height)

  GiniIndex &lt;- (0.5 - sum(calcGini$area))/0.5
  
  print(paste0(&quot;Gini Index is: &quot;, GiniIndex))  
  print(p)
} </code></pre>
<div id="data-and-methods" class="section level2">
<h2>Data and Methods</h2>
<p>The data set is the dataCar in insuranceDate library. I used the following explanatory variables:</p>
<table>
<thead>
<tr class="header">
<th>variables</th>
<th>note</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>veh_value</td>
<td>in $10k unit; an approximation of vehicle symbol</td>
</tr>
<tr class="even">
<td>exposure</td>
<td>in 0~1; probably earned car year</td>
</tr>
<tr class="odd">
<td>numclaims</td>
<td>claim count</td>
</tr>
<tr class="even">
<td>claimcst0</td>
<td>loss amount</td>
</tr>
<tr class="odd">
<td>veh_body</td>
<td>body type, a categorical variable</td>
</tr>
<tr class="even">
<td>veh_age</td>
<td></td>
</tr>
<tr class="odd">
<td>gender</td>
<td>a categorical veritable</td>
</tr>
<tr class="even">
<td>area</td>
<td>a categorical variable; an approximation of the territory agecat</td>
</tr>
</tbody>
</table>
<pre class="r"><code>library(scales)
library(insuranceData)
data(dataCar)
str(dataCar)</code></pre>
<pre><code>## &#39;data.frame&#39;:    67856 obs. of  11 variables:
##  $ veh_value: num  1.06 1.03 3.26 4.14 0.72 2.01 1.6 1.47 0.52 0.38 ...
##  $ exposure : num  0.304 0.649 0.569 0.318 0.649 ...
##  $ clm      : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ numclaims: int  0 0 0 0 0 0 0 0 0 0 ...
##  $ claimcst0: num  0 0 0 0 0 0 0 0 0 0 ...
##  $ veh_body : Factor w/ 13 levels &quot;BUS&quot;,&quot;CONVT&quot;,..: 4 4 13 11 4 5 8 4 4 4 ...
##  $ veh_age  : int  3 2 2 2 4 3 3 2 4 4 ...
##  $ gender   : Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 1 1 1 1 1 2 2 2 1 1 ...
##  $ area     : Factor w/ 6 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,..: 3 1 5 4 3 3 1 2 1 2 ...
##  $ agecat   : int  2 4 2 2 2 4 4 6 3 4 ...
##  $ X_OBSTAT_: Factor w/ 1 level &quot;01101    0    0    0&quot;: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>Usually the insurance data set is big. To make the the code to be easily scaled up, I used h2o in the modeling.</p>
<pre class="r"><code>library(h2o)

h2o.init(
  nthreads = -1,
  max_mem_size = &quot;4G&quot;
)</code></pre>
<pre><code>## 
## H2O is not running yet, starting it now...
## 
## Note:  In case of errors look at the following log files:
##     C:\Users\lijia\AppData\Local\Temp\RtmpuyCOJu/h2o_lijia_started_from_r.out
##     C:\Users\lijia\AppData\Local\Temp\RtmpuyCOJu/h2o_lijia_started_from_r.err
## 
## 
## Starting H2O JVM and connecting: . Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         5 seconds 980 milliseconds 
##     H2O cluster version:        3.16.0.2 
##     H2O cluster version age:    4 months and 18 days !!! 
##     H2O cluster name:           H2O_started_from_R_lijia_pdh030 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   3.56 GB 
##     H2O cluster total cores:    8 
##     H2O cluster allowed cores:  8 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         Algos, AutoML, Core V3, Core V4 
##     R Version:                  R version 3.4.4 (2018-03-15)</code></pre>
<pre class="r"><code>h2o.no_progress()

df &lt;- as.h2o(dataCar)</code></pre>
<p>Then, I subset the data and build the frequency and severity as the responses variables. Please note that 93% records have the missing sevrity.</p>
<pre class="r"><code>varList &lt;- c(&quot;veh_value&quot;,
                &quot;exposure&quot;,
                &quot;numclaims&quot;,
                &quot;claimcst0&quot;,
                &quot;veh_body&quot;,
                &quot;veh_age&quot;,
                &quot;gender&quot;,
                &quot;area&quot;,
                &quot;agecat&quot;
                ) 
df &lt;- df[, varList]
df$PP &lt;- df$claimcst0 / df$exposure

# the features used in modeling
varModel &lt;- c(&quot;veh_value&quot;,
              &quot;veh_body&quot;,
              &quot;veh_age&quot;,
              &quot;gender&quot;,
              &quot;area&quot;,
              &quot;agecat&quot;) 

df$frequency &lt;- df$numclaims / df$exposure
df$severity &lt;- df$claimcst0 / df$numclaims

print(&quot;Percentage of missing values in frequency and severity:&quot;)</code></pre>
<pre><code>## [1] &quot;Percentage of missing values in frequency and severity:&quot;</code></pre>
<pre class="r"><code>percent(h2o.sum(is.na(df$frequency))/nrow(df))</code></pre>
<pre><code>## [1] &quot;0%&quot;</code></pre>
<pre class="r"><code>percent(h2o.sum(is.na(df$severity))/nrow(df))</code></pre>
<pre><code>## [1] &quot;93.2%&quot;</code></pre>
<pre class="r"><code># split data to train and test
parts &lt;- h2o.splitFrame(data = df, ratios = 0.8)
train &lt;- parts[[1]]
test &lt;- parts[[2]]

train &lt;- df
test &lt;- df</code></pre>
</div>
<div id="glm" class="section level2">
<h2>GLM</h2>
<p>First, predict the frequency:</p>
<pre class="r"><code># frequency
train$logExp &lt;- h2o.log(train$exposure) # offset

freqFit = h2o.glm(y = &quot;numclaims&quot;,
                  x = varModel,
                  training_frame = train,
                  offset_column = &quot;logExp&quot;,
                  family = &quot;poisson&quot;,
                  link = &quot;log&quot;,
                  missing_values_handling = &quot;Skip&quot;,
                  solver = &quot;IRLSM&quot;,
                  # nfolds = 5,
                  lambda = 0,
                  remove_collinear_columns = T,
                  # weights_column = &quot;dateWeight&quot;,
                  compute_p_values = T
)</code></pre>
<p>Then, predict the severity:</p>
<pre class="r"><code># seveaity
sevFit = h2o.glm(y = &quot;severity&quot;,
                 x = varModel,
                 training_frame = train,
                 family = &quot;gamma&quot;,
                 link = &quot;log&quot;,
                 missing_values_handling = &quot;Skip&quot;,
                 solver = &quot;IRLSM&quot;,
                 # nfolds = 5,
                 lambda = 0,
                 remove_collinear_columns = T,
                 # weights_column = &quot;dateWeight&quot;,
                 compute_p_values = T
)</code></pre>
<p>To evaluate the GLM modeling, the predicted pure premium was calculated using the frequency and severity factors. The predict function cannot be used directly because the GLM does not model the frequency directly. The frequency was predicted using claim count offset by exposure. Thus, the predicted pure premium was calculated by using the model estimate and intercept. Here, the factors <span class="math inline">\(e^{estimate}\)</span> are summarized:</p>
<pre class="r"><code>factorDF &lt;-
  summaryFactorGLM(list(frequency = freqFit, severity = sevFit)) %&gt;% 
  select(parameter, level, factor)</code></pre>
<div id="evaluation" class="section level3">
<h3>Evaluation</h3>
<p>Calculate the predicted pure premium by <span class="math inline">\(e^{\beta_0}e^{\beta_1x_1}e^{\beta_2x_2}...\)</span>. Here <span class="math inline">\(\beta_0\)</span> is the intercept, <span class="math inline">\(\beta_1 \beta_2 \beta_3...\)</span> are the estimate, and <span class="math inline">\(\x_1 \x_2 \x_3...\)</span> are the explanatory variables.</p>
<p>The predicted number is smaller than the real one. Because pure premium is missing in most of the records, the MAE is not a good check point of fitting quality.</p>
<pre class="r"><code># send data to base R
evaDF &lt;- as.data.frame(test)

# in modeling data set, convert factor to character
evaDF &lt;- evaDF %&gt;%
  mutate(veh_body = as.character(veh_body),
         gender = as.character(gender),
         area = as.character(area)
           )

# continuouse variables: attach the factor^x as the predicted PP
for (var in c(&quot;veh_value&quot;, &quot;veh_age&quot;, &quot;agecat&quot;)) {
  newVar &lt;- paste0(&quot;rater_&quot;, var)
  quoteVar &lt;- rlang::sym(var)
  
  oneFactor &lt;- factorDF %&gt;% 
    filter(parameter == var) %&gt;% 
    select(factor) %&gt;% 
    pull()
  
  evaDF &lt;- evaDF %&gt;% 
    mutate(!!newVar := oneFactor^(!!quoteVar))
}
  
# categorical veriables: attach the factor with the same level
for (var in c(&quot;veh_body&quot;, &quot;gender&quot;, &quot;area&quot;)) {
  newVar &lt;- paste0(&quot;rater_&quot;, var)

  oneFactor &lt;- factorDF %&gt;%
    filter(parameter == var) %&gt;% 
    select(level, factor)

  names(oneFactor) &lt;- c(var, newVar)
  
  evaDF &lt;- left_join(evaDF,
                     oneFactor,
                     by = var,
                     all.x = T)
  # the missing value is the base level, assign it as 1
  evaDF[is.na(evaDF[[newVar]]), newVar] &lt;- 1
}

# add the intercept
intcpt &lt;- factorDF %&gt;%
  filter(parameter == &quot;freqIntercept&quot; | parameter == &quot;sevIntercept&quot;) %&gt;% 
  select(factor) 

evaDF$rater_intecept &lt;- intcpt[1,1] * intcpt[2,1]
  
# multiply the factors and intercept to get the prediced PP
evaDF &lt;- evaDF %&gt;% 
  mutate(
      predict_PP = 
      rater_veh_value *
      rater_veh_age *
      rater_veh_age *
      rater_veh_body *
      rater_gender *
      rater_area *
      rater_intecept
  )

evaluateModel(evaDF)</code></pre>
<pre><code>## [1] &quot;The percent of predicted total pure premium: 66.6%&quot;
## [1] &quot;The MAE of pure premium is: 1193.55&quot;
## # A tibble: 10 x 4
##    tier                predictPP tier1               realPP
##    &lt;fct&gt;               &lt;chr&gt;     &lt;fct&gt;               &lt;chr&gt; 
##  1 (-31.2,3.18e+03]    $232      (-31.5,3.18e+03]    $0    
##  2 (3.18e+03,6.36e+03] $221.19   (3.18e+03,6.36e+03] $0    
##  3 (6.36e+03,9.54e+03] $253.29   (6.36e+03,9.54e+03] $0    
##  4 (9.54e+03,1.27e+04] $273.70   (9.54e+03,1.27e+04] $0    
##  5 (1.27e+04,1.59e+04] $290.63   (1.27e+04,1.59e+04] $0    
##  6 (1.59e+04,1.91e+04] $229.09   (1.59e+04,1.91e+04] $0    
##  7 (1.91e+04,2.23e+04] $346.34   (1.91e+04,2.23e+04] $0    
##  8 (2.23e+04,2.54e+04] $315.38   (2.23e+04,2.54e+04] $0    
##  9 (2.54e+04,2.86e+04] $310.02   (2.54e+04,2.86e+04] $0    
## 10 (2.86e+04,3.18e+04] $457.37   (2.86e+04,3.18e+04] $2,929
## [1] &quot;Gini Index is: 0.0966854404679639&quot;</code></pre>
<p><img src="/post/2018-02-25-insurance-predictive-modeling_files/figure-html/unnamed-chunk-8-1.svg" width="576" /></p>
</div>
</div>
<div id="glm-tweedie" class="section level2">
<h2>GLM tweedie</h2>
<pre class="r"><code># modelDF &lt;- modelDF[modelDF$numclaims != 0, ]
fitPP &lt;- h2o.glm(
  y = &quot;PP&quot;,
  x = varModel,
  # nfolds = 5,
  training_frame = train,
  family = &#39;tweedie&#39;,
  tweedie_variance_power = 1.5
)

pred &lt;- h2o.predict(fitPP, test)

names(pred)[1] &lt;- c(&quot;predict_PP&quot;)

test$predict_PP &lt;- NULL
test &lt;- h2o.cbind(test, pred$predict_PP)

evaluateModel(test)</code></pre>
<pre><code>## [1] &quot;The percent of predicted total pure premium: 90.5%&quot;
## [1] &quot;The MAE of pure premium is: 1356.67&quot;
## # A tibble: 10 x 4
##    tier                predictPP tier1               realPP
##    &lt;fct&gt;               &lt;chr&gt;     &lt;fct&gt;               &lt;chr&gt; 
##  1 (-31,3.18e+03]      $234.09   (-31.5,3.18e+03]    $0    
##  2 (3.18e+03,6.36e+03] $272.58   (3.18e+03,6.36e+03] $0    
##  3 (6.36e+03,9.54e+03] $232.02   (6.36e+03,9.54e+03] $0    
##  4 (9.54e+03,1.27e+04] $311.70   (9.54e+03,1.27e+04] $0    
##  5 (1.27e+04,1.59e+04] $261.07   (1.27e+04,1.59e+04] $0    
##  6 (1.59e+04,1.91e+04] $322.07   (1.59e+04,1.91e+04] $0    
##  7 (1.91e+04,2.23e+04] $304.28   (1.91e+04,2.23e+04] $0    
##  8 (2.23e+04,2.54e+04] $314.41   (2.23e+04,2.54e+04] $0    
##  9 (2.54e+04,2.86e+04] $333.63   (2.54e+04,2.86e+04] $0    
## 10 (2.86e+04,3.18e+04] $343.18   (2.86e+04,3.18e+04] $2,929
## [1] &quot;Gini Index is: 0.0553388298587972&quot;</code></pre>
<p><img src="/post/2018-02-25-insurance-predictive-modeling_files/figure-html/unnamed-chunk-9-1.svg" width="576" /></p>
</div>
<div id="random-forest" class="section level2">
<h2>Random Forest</h2>
<pre class="r"><code># modelDF &lt;- modelDF[modelDF$numclaims != 0, ]
fitRF &lt;- h2o.randomForest(
  y = &quot;PP&quot;,
  x = varModel,
  # nfolds = 5,
  training_frame = train
)

pred &lt;- h2o.predict(fitRF, test)

names(pred)[1] &lt;- c(&quot;predict_PP&quot;)

test$predict_PP &lt;- NULL
test &lt;- h2o.cbind(test, pred$predict_PP)

evaluateModel(test)</code></pre>
<pre><code>## [1] &quot;The percent of predicted total pure premium: 101%&quot;
## [1] &quot;The MAE of pure premium is: 980.18&quot;
## # A tibble: 10 x 4
##    tier                predictPP tier1               realPP
##    &lt;fct&gt;               &lt;chr&gt;     &lt;fct&gt;               &lt;chr&gt; 
##  1 (-31.2,3.18e+03]    $0        (-31.5,3.18e+03]    $0    
##  2 (3.18e+03,6.36e+03] $0.31     (3.18e+03,6.36e+03] $0    
##  3 (6.36e+03,9.54e+03] $1.14     (6.36e+03,9.54e+03] $0    
##  4 (9.54e+03,1.27e+04] $4.04     (9.54e+03,1.27e+04] $0    
##  5 (1.27e+04,1.59e+04] $8.63     (1.27e+04,1.59e+04] $0    
##  6 (1.59e+04,1.91e+04] $22.39    (1.59e+04,1.91e+04] $0    
##  7 (1.91e+04,2.23e+04] $46.51    (1.91e+04,2.23e+04] $0    
##  8 (2.23e+04,2.54e+04] $119.63   (2.23e+04,2.54e+04] $0    
##  9 (2.54e+04,2.86e+04] $343.98   (2.54e+04,2.86e+04] $0    
## 10 (2.86e+04,3.18e+04] $2,382.23 (2.86e+04,3.18e+04] $2,929
## [1] &quot;Gini Index is: 0.872865045443628&quot;</code></pre>
<p><img src="/post/2018-02-25-insurance-predictive-modeling_files/figure-html/unnamed-chunk-10-1.svg" width="576" /></p>
</div>
<div id="gbm" class="section level2">
<h2>GBM</h2>
<pre class="r"><code># modelDF &lt;- modelDF[modelDF$numclaims != 0, ]
fitGBM &lt;- h2o.gbm(
  y = &quot;PP&quot;,
  x = varModel,
  # nfolds = 5,
  training_frame = train
)

pred &lt;- h2o.predict(fitGBM, test)

names(pred)[1] &lt;- c(&quot;predict_PP&quot;)

test$predict_PP &lt;- NULL
test &lt;- h2o.cbind(test, pred$predict_PP)

evaluateModel(test)</code></pre>
<pre><code>## [1] &quot;The percent of predicted total pure premium: 100%&quot;
## [1] &quot;The MAE of pure premium is: 1428.05&quot;
## # A tibble: 10 x 4
##    tier                predictPP tier1               realPP
##    &lt;fct&gt;               &lt;chr&gt;     &lt;fct&gt;               &lt;chr&gt; 
##  1 (-31.5,3.18e+03]    $173.91   (-31.5,3.18e+03]    $0    
##  2 (3.18e+03,6.36e+03] $242.73   (3.18e+03,6.36e+03] $0    
##  3 (6.36e+03,9.54e+03] $292.03   (6.36e+03,9.54e+03] $0    
##  4 (9.54e+03,1.27e+04] $252.56   (9.54e+03,1.27e+04] $0    
##  5 (1.27e+04,1.59e+04] $271.46   (1.27e+04,1.59e+04] $0    
##  6 (1.59e+04,1.91e+04] $248.65   (1.59e+04,1.91e+04] $0    
##  7 (1.91e+04,2.23e+04] $274.95   (1.91e+04,2.23e+04] $0    
##  8 (2.23e+04,2.54e+04] $265.11   (2.23e+04,2.54e+04] $0    
##  9 (2.54e+04,2.86e+04] $369.29   (2.54e+04,2.86e+04] $0    
## 10 (2.86e+04,3.18e+04] $538.36   (2.86e+04,3.18e+04] $2,929
## [1] &quot;Gini Index is: 0.130182025963855&quot;</code></pre>
<p><img src="/post/2018-02-25-insurance-predictive-modeling_files/figure-html/unnamed-chunk-11-1.svg" width="576" /></p>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdn.bootcss.com/highlight.js/9.11.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.11.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

